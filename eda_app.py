import streamlit as st
import pandas as pd
import plotly.express as px
import collections
from datetime import date
import json

# --- Page Configuration ---
st.set_page_config(
    page_title="Monitor de Noticias de EnergÃ­a y Minerales",
    page_icon="ğŸ“Š",
    layout="wide",
)

# --- Data Loading ---
@st.cache_data
def load_data(path):
    """Loads the news data from a CSV file."""
    try:
        df = pd.read_csv(path)
        df['publishDate'] = pd.to_datetime(df['publishDate'], errors='coerce')
        return df
    except FileNotFoundError:
        st.error(f"Error: No se pudo encontrar el archivo en la ruta: {path}")
        return None

df_news = load_data('df_news_final.csv')

if df_news is not None:
    # --- Sidebar Navigation ---
    st.sidebar.title("NavegaciÃ³n")
    analysis_option = st.sidebar.radio(
        "Selecciona una secciÃ³n:",
        (
            "MetodologÃ­a",
            "Distribuciones",
            "Top 20 Noticias Relevantes",
            "Noticias AnÃ³malas",
            "AnÃ¡lisis de Palabras Clave",
            "Base de Datos",
        ),
    )

    # --- Semantic Search Option ---
    st.sidebar.subheader("ğŸ” Opciones de BÃºsqueda SemÃ¡ntica")
    
    semantic_search_mode = st.sidebar.selectbox(
        "Selecciona una opciÃ³n (para volver a secciones superiores selecciona opciÃ³n 'Desactivada'):",
        ["Desactivada", "Palabras Clave", "Embeddings Avanzados"]
    )

    # --- Main Content ---
    st.title("Monitor de Noticias de EnergÃ­a y Minerales")
    st.markdown("Resultados preliminares de proceso experimental de captura y anÃ¡lisis de noticias.")

    # --- IntegraciÃ³n de buscadores semÃ¡nticos ---
    if semantic_search_mode != "Desactivada":
        if semantic_search_mode == "Palabras Clave":
            import semantic_search_app
            semantic_search_app.run_search()
        elif semantic_search_mode == "Embeddings Avanzados":
            import semantic_search_pro
            semantic_search_pro.run_search()
        st.stop()

    # Cargar los tÃ­tulos de los topics
    with open('topic_titles.json', encoding='utf-8') as f:
        topic_titles = json.load(f)

    if analysis_option == "MetodologÃ­a":
        st.header("MetodologÃ­a de RecolecciÃ³n y Procesamiento de Noticias")

        st.markdown("""
Se diseÃ±Ã³ un proceso de bÃºsqueda automatizada a partir de un conjunto de consultas predefinidas en inglÃ©s y espaÃ±ol, orientadas a temas relacionados con minerales crÃ­ticos, energÃ­a y geopolÃ­tica de Ã©stos. Las consultas se ejecutaron en un metabuscador, el cual permite buscar simultÃ¡neamente en varios motores de bÃºsqueda. Para cada set de consultas, se especificÃ³ el idioma correspondiente y se configurÃ³ la bÃºsqueda para obtener Ãºnicamente los primeros resultados de cada consulta, sin restricciÃ³n de fecha (aunque es posible ampliar la bÃºsqueda a mÃ¡s pÃ¡ginas de resultados, en este caso experimental se limitÃ³ a la primera pÃ¡gina de resultados por cada consulta).

*Para este ejercicio experimental se ejecutÃ³ el proceso el 13 de julio de 2025, obteniendo resultados de noticias mÃ¡s recientes hasta esa fecha.*
                    
**Consultas utilizadas en espaÃ±ol:**
- 'Ã³rdenes ejecutivas de Trump respecto a minerales crÃ­ticos'
- 'minerales crÃ­ticos'
- 'aranceles estados unidos a minerales crÃ­ticos'
- 'Ã³rdenes ejecutivas de Trump respecto a energÃ­a, seguridad energÃ©tica, autosuficiencia energÃ©tica'
- 'decisiones y Ã³rdenes ejecutivas de estados unidos respecto a desregulaciÃ³n del sector energÃ©tico'
- 'polÃ­ticas y decisiones de fomento a combustibles fÃ³siles'
- 'restricciones a la exportaciÃ³n de minerales crÃ­ticos China'
- 'incentivos a la producciÃ³n de minerales estratÃ©gicos Estados Unidos UniÃ³n Europea'
- 'geopolÃ­tica de minerales crÃ­ticos'
- 'tierras raras'
- 'minerÃ­a de aguas profundas'

**Consultas utilizadas en inglÃ©s:**
- 'Trump executive orders on critical minerals'
- 'critical minerals'
- 'U.S. tariffs on critical minerals'
- 'Trump executive orders on energy, energy independence, and energy security'
- 'U.S. executive decisions and orders on energy sector deregulation'
- 'policies and decisions supporting fossil fuel development'
- 'China export restrictions on critical minerals OR rare earths'
- 'US or EU incentives for critical minerals production OR supply chain resilience'
- 'geopolitics of critic minerals'
- 'rare earth'
- 'deep sea mining'

En total, se realizaron 11 consultas por cada idioma, obteniendo solo la primera pÃ¡gina de resultados para cada una.

### Resultados

El proceso arrojÃ³ un total de **1617 registros**. Dado que los motores de bÃºsqueda tienden a priorizar la informaciÃ³n mÃ¡s reciente, aproximadamente el **60% de los datos corresponden al aÃ±o 2025** (y el 90% de los datos con fecha no vacÃ­a, ya que existen mÃ¡s de 500 registros sin fecha en los metadatos).

La base de datos resultante contiene 23 columnas, entre las que destacan:  
- **url**: enlace a la noticia  
- **title**: tÃ­tulo  
- **content**: contenido  
- **engine**: motor de bÃºsqueda  
- **source**: fuente  
- **publishDate**: fecha de publicaciÃ³n  
- **query**: consulta utilizada  
- **language**: idioma  
- **topic_id**: identificador temÃ¡tico  
- **enhanced_relevance_score**: puntaje de relevancia  
- **anomaly_label**: etiqueta de anomalÃ­a  
- ...entre otras variables Ãºtiles para el anÃ¡lisis exploratorio y temÃ¡tico.
    """)

    if analysis_option == "Distribuciones":
        st.header("AnÃ¡lisis de Distribuciones")
        st.write("VisualizaciÃ³n de la distribuciÃ³n de variables en el conjunto de datos. Se incluyen variables categÃ³ricas como idioma, consulta realizada, motor de bÃºsqueda, fuente. AdemÃ¡s se presentan agrupaciones automÃ¡ticas por clÃºster temÃ¡tico, asÃ­ como la distribuciÃ³n por fecha de publicaciÃ³n.")

        # --- Categorical Variables ---
        st.subheader("Variables CategÃ³ricas")
        categorical_cols = ["language", "query", "engine", "source"]
        for col in categorical_cols:
            if col == "query":
                # Contar ocurrencias y asociar idioma principal
                query_counts = (
                    df_news.groupby('query')
                    .agg(count=('query', 'size'), language=('language', lambda x: x.mode()[0] if not x.mode().empty else ''))
                    .reset_index()
                )
                max_label_length = 30
                query_counts['query_trunc'] = query_counts['query'].apply(
                    lambda x: x[:max_label_length] + '...' if len(x) > max_label_length else x
                )
                color_map = {
                    'es': '#4FC3F7',      # azul claro
                    'espaÃ±ol': '#4FC3F7',
                    'en': '#1565C0',      # azul oscuro
                    'inglÃ©s': '#1565C0'
                }
                fig = px.bar(
                    query_counts,
                    x='query_trunc',
                    y='count',
                    color='language',
                    color_discrete_map=color_map,
                    title="DistribuciÃ³n por query",
                    labels={'query_trunc': 'Query', 'count': 'Cantidad', 'language': 'Idioma'},
                    hover_data=['query', 'language'],
                )
                fig.update_layout(xaxis={'categoryorder':'total descending'})
                st.plotly_chart(fig)
            elif col == "source":
                # Tu cÃ³digo actual para source (barras simples, sin color por idioma)
                counts = df_news[col].value_counts().reset_index()
                counts.columns = [col, 'count']
                max_label_length = 30
                counts[f'{col}_trunc'] = counts[col].apply(
                    lambda x: x[:max_label_length] + '...' if len(x) > max_label_length else x
                )
                fig = px.bar(
                    counts,
                    x=f'{col}_trunc',
                    y='count',
                    title=f"DistribuciÃ³n por {col}",
                    labels={f'{col}_trunc': col.capitalize(), 'count': 'Cantidad'},
                    hover_data=[col],
                )
                fig.update_layout(xaxis={'categoryorder':'total descending'})
                st.plotly_chart(fig)
            else:
                fig = px.pie(df_news, names=col, title=f"DistribuciÃ³n por {col}", hole=0.3)
                st.plotly_chart(fig)

        # --- Numerical Variables ---
        st.subheader("ClÃºsteres TemÃ¡ticos")
        st.write("VisualizaciÃ³n grupos de noticias a travÃ©s de clustering automÃ¡tico.")
        # Crear columna descriptiva para topic_id
        df_news['topic_label'] = df_news['topic_id'].astype(str).map(topic_titles)

        # Calcular el conteo por tema y ordenar de mayor a menor
        topic_counts = df_news['topic_label'].value_counts().sort_values(ascending=False)
        ordered_labels = topic_counts.index.tolist()

        # Graficar el histograma con el eje x ordenado
        fig_topic = px.histogram(
            df_news,
            x="topic_label",
            category_orders={"topic_label": ordered_labels},
            title="DistribuciÃ³n por Tema (agrupaciÃ³n no supervisada)",
            labels={"topic_label": "Tema", "count": "Cantidad"}
        )
        fig_topic.update_xaxes(type='category', categoryorder='array', categoryarray=ordered_labels)
        fig_topic.update_layout(bargap=0.2)
        st.plotly_chart(fig_topic)

        st.markdown("### DistribuciÃ³n por fecha de publicaciÃ³n")
        df_filtered_date = df_news.dropna(subset=['publishDate']).copy()
        df_filtered_date['year_month'] = df_filtered_date['publishDate'].dt.to_period('M').astype(str)
        df_filtered_date['date_str'] = df_filtered_date['publishDate'].dt.strftime('%Y-%m-%d')

        # Definir el rango de fechas para el slider (convertir a date)
        min_date = df_filtered_date['publishDate'].min().date()
        max_date = df_filtered_date['publishDate'].max().date()

        # Slider para seleccionar el rango de fechas
        date_range = st.slider(
            "Selecciona el rango de fechas:",
            min_value=min_date,
            max_value=max_date,
            value=(min_date, max_date),
            format="YYYY-MM-DD"
        )

        # Filtrar el DataFrame segÃºn el rango seleccionado
        df_filtered_date = df_filtered_date[
            (df_filtered_date['publishDate'].dt.date >= date_range[0]) &
            (df_filtered_date['publishDate'].dt.date <= date_range[1])
        ]

        # Decidir el nivel de agregaciÃ³n
        range_days = (date_range[1] - date_range[0]).days
        if range_days > 60:
            x_col = 'year_month'
            x_title = "AÃ±o-Mes"
        else:
            x_col = 'date_str'
            x_title = "Fecha"

        # Ordenar el DataFrame por fecha
        df_filtered_date = df_filtered_date.sort_values('publishDate')

        # Graficar
        fig_date = px.histogram(
            df_filtered_date,
            x=x_col,
            title=f"DistribuciÃ³n por Fecha de PublicaciÃ³n ({x_title})",
            labels={x_col: x_title, "count": "Cantidad"}
        )
        fig_date.update_xaxes(type='category', categoryorder='category ascending')
        st.plotly_chart(fig_date)


    elif analysis_option == "Top 20 Noticias Relevantes":
        st.header("Top 20 Noticias por Relevancia (ver detalles de scoring)")

        with st.expander("â„¹ï¸ Detalles del scoring"):
            st.markdown("""
## Sistema experimental de Scoring para Noticias

El sistema de scoring evalÃºa la relevancia de noticias segÃºn mÃºltiples criterios ponderados, generando un puntaje normalizado entre 0 y 1 para priorizar informaciÃ³n estratÃ©gica.

---

## Componentes del Sistema de Scoring

### 1. **Criterios de EvaluaciÃ³n y Pesos**

| **CategorÃ­a** | **Peso** | **DescripciÃ³n** | **Ejemplos de TÃ©rminos** |
|---|---|---|---|
| **ğŸŒ AmÃ©rica Latina** | 3.0 | Enfoque geogrÃ¡fico prioritario | "latin america", "chile", "amÃ©rica latina", "caribe" |
| **ğŸ“‹ Ã“rdenes Ejecutivas** | 2.8 | Decisiones presidenciales directas | "executive order", "orden ejecutiva", "presidential directive" |
| **âš¡ Minerales CrÃ­ticos** | 2.5 | Recursos estratÃ©gicos clave | "critical minerals", "lithium", "minerales crÃ­ticos", "litio" |
| **ğŸ”‹ EnergÃ­as Renovables** | 2.2 | TransiciÃ³n energÃ©tica | "renewable energy", "solar", "energÃ­a renovable", "eÃ³lica" |
| **ğŸ›ï¸ PolÃ­ticas Generales** | 2.0 | PolÃ­ticas estadounidenses | "policy change", "tariff", "cambio de polÃ­tica", "arancel" |
| **âš™ï¸ PolÃ­tica EnergÃ©tica** | 2.0 | Estrategias energÃ©ticas | "energy policy", "energy security", "polÃ­tica energÃ©tica" |
| **â›ï¸ Actividades Mineras** | 1.8 | Operaciones extractivas | "mining operations", "extraction", "operaciones mineras" |
| **ğŸ›¢ï¸ Combustibles FÃ³siles** | 1.5 | EnergÃ­as tradicionales | "fossil fuels", "oil production", "combustibles fÃ³siles" |
| **ğŸ¥‰ BonificaciÃ³n Cobre** | 1.2 | Mineral especÃ­fico de interÃ©s | "copper", "cobre" |

---

### 2. **Autoridad de Fuentes**

| **Nivel** | **Peso** | **Tipo de Fuente** | **Ejemplos** |
|---|---|---|---|
| **Tier 1** | 2.0 | Gubernamental y financiera premium | whitehouse.gov, reuters.com, bloomberg.com |
| **Tier 2** | 1.5 | Medios establecidos | nytimes.com, wsj.com, bbc.com, cnn.com |
| **Tier 3** | 1.2 | Fuentes especializadas | mining.com, energycentral.com, law360.com |

---

### 3. **Relevancia Temporal**

| **AntigÃ¼edad** | **Multiplicador** | **DescripciÃ³n** |
|---|---|---|
| **0-7 dÃ­as** | 0.9-1.0 | MÃ¡xima relevancia |
| **8-15 dÃ­as** | 0.7-0.9 | Alta relevancia |
| **16-30 dÃ­as** | 0.4-0.7 | Relevancia media |
| **30+ dÃ­as** | 0.1-0.4 | Relevancia mÃ­nima |
| **Fecha faltante** | 0.7 | PenalizaciÃ³n por dato incompleto |

---

### 4. **Factores Adicionales**

| **Factor** | **Peso** | **CondiciÃ³n** |
|---|---|---|
| **Coincidencia con Query** | +0.8 | TÃ©rminos relevantes en consulta original |
| **Multiidioma** | N/A | DetecciÃ³n automÃ¡tica inglÃ©s/espaÃ±ol |
| **NormalizaciÃ³n** | Ã·10 | Score final entre 0-1 |

---

## ğŸ” MetodologÃ­a de BÃºsqueda

### **TÃ©cnicas Implementadas:**
- **Word Boundaries**: Evita coincidencias parciales (`\b palabra \b`)
- **NormalizaciÃ³n**: ConversiÃ³n a minÃºsculas y limpieza
- **BÃºsqueda Multiidioma**: TÃ©rminos en inglÃ©s y espaÃ±ol
- **ValidaciÃ³n de Datos**: Manejo robusto de valores nulos

---

## ğŸ“ˆ InterpretaciÃ³n de Resultados

### **Rangos de Score:**
| **Rango** | **InterpretaciÃ³n** | **AcciÃ³n Recomendada** |
|---|---|---|
| **0.8 - 1.0** | Altamente relevante | Prioridad mÃ¡xima |
| **0.6 - 0.8** | Muy relevante | RevisiÃ³n prioritaria |
| **0.4 - 0.6** | Moderadamente relevante | RevisiÃ³n secundaria |
| **0.2 - 0.4** | Poco relevante | Monitoreo |
| **0.0 - 0.2** | Baja relevancia | Archivo |

---

## ğŸ¯ Ejemplo de CÃ¡lculo

### **Noticia hipotÃ©tica:**
*"Trump firma orden ejecutiva sobre minerales crÃ­ticos en AmÃ©rica Latina"*

| **Componente** | **Coincidencia** | **Peso** | **Puntos** |
|---|---|---|---|
| AmÃ©rica Latina | âœ… | 3.0 | 3.0 |
| Ã“rdenes Ejecutivas | âœ… | 2.8 | 2.8 |
| Minerales CrÃ­ticos | âœ… | 2.5 | 2.5 |
| Fuente (Reuters) | âœ… | 2.0 | 2.0 |
| Relevancia Temporal | 2 dÃ­as | x0.95 | - |
| **Score Bruto** | | | **9.8** |
| **Score Normalizado** | | Ã·10 x0.95 | **0.93** |

---

## âš™ï¸ ConfiguraciÃ³n del Sistema

### **ParÃ¡metros Ajustables:**
- **Time Decay Factor**: 0.05 (menos agresivo)
- **Max Days Relevant**: 30 dÃ­as
- **Date Penalty**: 0.7 (70% del score)
- **Query Bonus**: 0.8 puntos adicionales

### **Ventajas del Sistema:**
âœ… **Objetividad**: Criterios cuantificables y transparentes  
âœ… **Flexibilidad**: Pesos ajustables segÃºn prioridades  
âœ… **Escalabilidad**: Procesamiento automatizado de grandes volÃºmenes  
âœ… **Trazabilidad**: Registro detallado de componentes del score  

---

## ğŸ“‹ Outputs del Sistema

### **MÃ©tricas Generadas:**
- Score de relevancia normalizado (0-1)
- Desglose por componentes
- EstadÃ­sticas descriptivas
- Ranking de noticias prioritarias
- Alertas por calidad de datos

### **Casos de Uso:**
1. **PriorizaciÃ³n diaria** de noticias para analistas
2. **Alertas automÃ¡ticas** para eventos crÃ­ticos
3. **Dashboards ejecutivos** con mÃ©tricas clave
4. **AnÃ¡lisis histÃ³rico** de tendencias informativas
            """)

        top_20_news = df_news.nlargest(20, 'enhanced_relevance_score')
        st.data_editor(top_20_news[['title', 'content', 'url','enhanced_relevance_score']],
                       column_config={
                           "url": st.column_config.LinkColumn("URL")
                       },
                       hide_index=True
                       )


    elif analysis_option == "Noticias AnÃ³malas":
        st.header("Listado de Noticias 'AnÃ³malas'")
        st.warning("Estas noticias fueron etiquetadas como anÃ³malas por un modelo de detecciÃ³n de anomalÃ­as. Se definen asÃ­ porque pueden ser noticias poco comunes y relevantes a las consultas o noticias que no tienen relaciÃ³n con los temas estudiadas recuperadas erroneÃ¡mente por los motores de bÃºsqueda. Estas requieren revisiÃ³n manual para determinar su relevancia.")
        anomalous_news = df_news[df_news['anomaly_label'] == -1].copy()
        anomalous_news = anomalous_news[['url', 'title']]
        st.data_editor(
            anomalous_news,
            column_config={
                "url": st.column_config.LinkColumn("URL")
            },
            hide_index=True
        )


    elif analysis_option == "AnÃ¡lisis de Palabras Clave":
        st.header("Top Palabras Clave por Tema")
        st.subheader("AnÃ¡lisis de set de palabras clave predifinidas")
        st.write("Para este anÃ¡lisis se utilizaron sets de palabras clave predefinidas para identificar tÃ©rminos relevantes en el texto completo de las noticias. Estos sets fueron diseÃ±ados para capturar temas relacionados con minerÃ­a y energÃ­a, puede mejorarse con sets de palabras clave mÃ¡s especÃ­ficos o personalizados segÃºn el contexto de interÃ©s.")

        # --- Keyword Processing para texto completo ---
        def find_terms_in_text(text, terms):
            """Busca tÃ©rminos en un texto y retorna los que aparecen."""
            if not isinstance(text, str):
                return []
            text_lower = text.lower()
            found_terms = [term for term in terms if term in text_lower]
            return found_terms

        # --- Mining Keywords ---
        st.subheader("MinerÃ­a")
        mining_terms = [
            "minerÃ­a", "mining", "mineral", "mineral", "cobre", "copper",
            "extracciÃ³n minera", "mining extraction", "oro", "gold",
            "plata", "silver", "litio", "lithium"
        ]
        df_news['mining_keywords'] = df_news['preprocessed_text_for_embeddings'].apply(
            lambda x: find_terms_in_text(x, mining_terms)
        )
        mining_keywords_list = [kw for sublist in df_news['mining_keywords'] for kw in sublist]
        mining_keyword_counts = collections.Counter(mining_keywords_list)

        if mining_keyword_counts:
            df_mining_keywords = pd.DataFrame(mining_keyword_counts.most_common(20), columns=['Keyword', 'Count'])
            fig_mining = px.bar(df_mining_keywords, x='Keyword', y='Count', title="Top 20 Palabras Clave de MinerÃ­a")
            st.plotly_chart(fig_mining)
        else:
            st.write("No se encontraron palabras clave de minerÃ­a con los tÃ©rminos de bÃºsqueda.")

        # --- Energy Keywords ---
        st.subheader("EnergÃ­a")
        energy_terms = [
            "energÃ­a", "energy", "energÃ­a verde", "green energy", "renovables", "renewables",
            "solar", "solar", "eÃ³lica", "wind", "wind power", "combustibles fÃ³siles", "fossil fuels",
            "petrÃ³leo", "oil", "petroleum", "carbÃ³n", "coal"
        ]
        df_news['energy_keywords'] = df_news['preprocessed_text_for_embeddings'].apply(
            lambda x: find_terms_in_text(x, energy_terms)
        )
        energy_keywords_list = [kw for sublist in df_news['energy_keywords'] for kw in sublist]
        energy_keyword_counts = collections.Counter(energy_keywords_list)

        if energy_keyword_counts:
            df_energy_keywords = pd.DataFrame(energy_keyword_counts.most_common(20), columns=['Keyword', 'Count'])
            fig_energy = px.bar(df_energy_keywords, x='Keyword', y='Count', title="Top 20 Palabras Clave de EnergÃ­a")
            st.plotly_chart(fig_energy)
        else:
            st.write("No se encontraron palabras clave de energÃ­a con los tÃ©rminos de bÃºsqueda.")

    elif analysis_option == "Base de Datos":
        st.header("Base de Datos de Noticias")
        st.write("Esta secciÃ³n permite explorar la base de datos de noticias procesadas. Se exluyen noticias sin fecha de publicaciÃ³n y se muestran las columnas mÃ¡s relevantes para el anÃ¡lisis.")

        # Crear columna descriptiva para topic_id
        df_news['topic_label'] = df_news['topic_id'].astype(str).map(topic_titles)

        # Inicializar filtros en session_state
        if "title_filter" not in st.session_state:
            st.session_state.title_filter = ""
        if "date_filter" not in st.session_state:
            min_date, max_date = df_news['publishDate'].min(), df_news['publishDate'].max()
            st.session_state.date_filter = (min_date.date(), max_date.date())
        if "topic_filter" not in st.session_state:
            st.session_state.topic_filter = "Todos"

        # BotÃ³n para limpiar filtros
        if st.button("Limpiar filtros"):
            st.session_state.title_filter = ""
            min_date, max_date = df_news['publishDate'].min(), df_news['publishDate'].max()
            st.session_state.date_filter = (min_date.date(), max_date.date())
            st.session_state.topic_filter = "Todos"

        # Filtros
        col1, col2, col3 = st.columns(3)
        with col1:
            title_filter = st.text_input("Buscar por tÃ­tulo (contiene):", st.session_state.title_filter, key="title_filter")
        with col2:
            min_date, max_date = df_news['publishDate'].min(), df_news['publishDate'].max()
            date_filter = st.date_input(
                "Filtrar por fecha de publicaciÃ³n:",
                value=st.session_state.date_filter,
                min_value=min_date.date(),
                max_value=max_date.date(),
                key="date_filter"
            )
        with col3:
            topic_options = ["Todos"] + [f"{k}: {v}" for k, v in topic_titles.items()]
            topic_filter = st.selectbox("Filtrar por Topic:", topic_options, key="topic_filter")

        # Aplicar filtros
        df_filtered = df_news.copy()
        if st.session_state.title_filter:
            df_filtered = df_filtered[df_filtered['title'].str.contains(st.session_state.title_filter, case=False, na=False)]
        if st.session_state.date_filter:
            df_filtered = df_filtered[
                (df_filtered['publishDate'].dt.date >= st.session_state.date_filter[0]) &
                (df_filtered['publishDate'].dt.date <= st.session_state.date_filter[1])
            ]
        if st.session_state.topic_filter != "Todos":
            topic_id_selected = st.session_state.topic_filter.split(":")[0]
            df_filtered = df_filtered[df_filtered['topic_id'].astype(str) == topic_id_selected]

        # Seleccionar columnas a mostrar
        columns_to_show = [
            "url", "title", "content","publishDate", "source", "enhanced_relevance_score", "topic_id", "topic_label"
        ]
        df_filtered = df_filtered[columns_to_show]

        # Texto dinÃ¡mico de resultados
        st.markdown(f"**Mostrando {len(df_filtered)} resultados.**")

        # Mostrar la tabla
        st.data_editor(
            df_filtered,
            column_config={
                "url": st.column_config.LinkColumn("URL"),
                "topic_label": st.column_config.TextColumn("Tema")
            },
            hide_index=True
        )

else:
    st.warning("No se pudieron cargar los datos. Por favor, verifica la ruta del archivo.")

